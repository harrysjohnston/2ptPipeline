[DEFAULT]
; config file variables, used as e.g. %(root)s/
; can define these variables in any section
; arguments can continue over multiple lines with indentation
; and may require // at line-end - see notes
root=

[jackknife]
; options for skyknife.py jackknife sample maker, using iterative quartering or kmeans clustering (command-line arg for latter)
; creates column in catalogues 'jackknife_ID' - can use w_pipeline.py jackknife functionality with
; own jackknife_ID column if desired, but ensure that it is base-1, as jackknife_ID==0 are always discarded
; catalogue to define jackknife
catalog=/path/to/uniform/randoms/catalogue
; additional catalogues for export of the same jackknife regions
exportto=
	/path/to/data/catalogue data_ra_name data_dec_name data_z_name //
	/path/to/another/data/catalogue data_ra_name data_dec_name data_z_name //
	/path/to/another/randoms/catalogue randoms_ra_name randoms_dec_name randoms_z_name
; w_pipeline.py option: measure 1=jackknife correlations only, 2=jackknife then main, 3=main then jackknife, 4=collect jackknife covariance, 0=main-only
run=0
; or, call the internal TreeCorr jackknife routine with treejack=N patches
; set treejack=0 to use external jackknife_ID. TreeCorr uses kmeans to define
; 2D (3D) jackknife patches for coordinate system RADEC (XYZ)
; only supported for w(theta) and xi_gg
treejack=0
; point to a saved set of treejack patches to use - if the file does not exist
; then new patches will be defined and saved here; delete the file to refresh
treejack_save=
; can specify limited subset (space-separated) of jackknife indices to correlate
numbers=
; 'catalog' columns for jackknife definition
ra_col=ra
dec_col=dec
z_col=z
; required for 3D jackknife
r_col=chi
; optionally subtract 360 from RA beyond this point
; recommended for RA=zero-crossing footprints
shiftra=360
; jackknife tuning parameters: target smallest degree scale
minimum_scale=0.2
; tolerance of area disparities, increase to <=1 for more tolerance
quarter_tol=0.7
; tolerance of angular size disparities, decrease to >=0 for more tolerance
scale_tol=0.3
; flag to slice jackknife regions into equal-number redshift subsets
do_3d=1
; minimum depth of slices, in units of 'r_col'
minimum_depth=150.
; min and max redshift of jackknife regions
zlims=0.1 0.3
; flag to make a plot of the jackknife and save as <catalog name without FITS extension>.jk.png
plot=1

[angular_correlations]
; give a path to a treecorr config
default=/path/to/treecorr/config/file
; or just specify the options here
; only FITS supported
file_type=FITS
; bin_slop can be overrided with command-line arg
bin_slop=0.01
; for angular correlations only:
ra_col=RA
dec_col=DEC
ra_units=degrees
dec_units=degrees
nbins=10
min_sep=3.
max_sep=100.
sep_units=arcmin
; compensated = with subtraction of signals around random points
nn_statistic=compensated
; command-line args and defaults override num_threads
; and verbosity, so do not bother defining in config
;num_threads=
;verbose=

# this section also describes 3D correlation parameters
[projected_correlations]
; only FITS supported
file_type=FITS
; AS=average shear/PW1=pair-weighted(fast)/PW2=pair-weighted(slow)
; determines normalisation, by DDs(AS), RDs(PW1), or RdRs(PW2)
gplus_estimator=PW1
; data catalogue column-names (barring scalar tracers, these must be the same for all data catalogues in this config)
; spherical
ra_col=ra
dec_col=dec
r_col=chi
ra_units=degrees
dec_units=degrees
ra_units=degrees
dec_units=degrees
; or Cartesian
x_col=
y_col=
z_col=
; shear1 and 2
g1_col=e1
g2_col=e2
; convergence (or any scalar); k1_col and k2_col refer to data1 and 2 below
; k2_col for xigk correlations, xikk will use both
k1_col=
k2_col=
; randoms catalogue column-names (must be the same for all randoms catalogues in this config)
rand_ra_col=
rand_dec_col=
rand_r_col=
rand_x_col=
rand_y_col=
rand_z_col=
; flag to multiply shear1 and/or 2 by -1
flip_g1=0
flip_g2=0
; supported are 'Periodic' for box correlations
; and 'Rperp' for projected RA/Dec/r correlations
metric=Rperp
; box size in units of 'z_col', if doing Periodic
period=
; bin_slop here can be overriden with the command-line arg
bin_slop=0.
; basic binning
nbins=7
min_sep=0.1
max_sep=30.
; line-of-sight binning (Rperp), either limits and nbins
min_rpar=-40
max_rpar=40
nbins_rpar=20
; or give specific edges, if wanting irregularity
rpar_edges=
; compensated = randoms-subtracted
compensated=1
; perform large line-of-sight separation tests, with 1.5*max_rpar (Rperp)
largePi=0
; save-out xi(rp, Pi) in pickle dicts <outfile>.p
save_3d=0

[catalogs]
; for every argument in this section, each row is an individual
; correlation, and must be //-separated. Python broadcasting
; rules apply: for given N correlations, all arguments should
; have N rows detailing args for each correlation, or 1 row
; to be carried over to all correlations. If data2/rand2 are blank,
; they take the values of data1/rand1, respectively.
; trailing // should not be a problem

; Choose corr_types from:
; 'wth' (angular clustering)
; 'wgg' (proj. clustering)
; 'wgp' (proj. density-shear)
; 'xigg' (3D clustering, currently only supported for XYZ)
; 'xigp' (3D density-shear, currently only supported for XYZ)
; 'xikk' (3D scalar-scalar, currently only supported for XYZ)
; 'xigk' (3D density-scalar, currently only supported for XYZ)
; can add more correlations on request
; scalar/shear fields described either by data2, or by both data1 and 2
corr_types=
	wgg //
	wgp
data1=
	/path/to/catalog1.fits
data2=
	/path/to/catalog2.fits
rand1=
	/path/to/randoms1.fits
rand2=
	/path/to/randoms2a.fits //
	/path/to/randoms2b.fits
; python syntax for cuts, using names of FITS catalogue columns
; special cut 'downsample(f)' randomly downsamples to fraction f
; can include other functions at the top of w_pipeline.py for making
; cuts per correlation, e.g. 'idmatch(r1, d1, r_ID, d_ID)' will
; select rand1 objects which have r_ID existing in data1 column d_ID
; (first 2 args must be in {r1, r2, d1, d2}, second 2 are FITS column-names)
data_cuts1=
	(some_column < some_value) //
	(RA > 20) & ((other_column < other_value) | (another_column > another_value**2))
; 'none' can be a place-holder for no cuts
data_cuts2=
	none //
	(RA > 20)
rand_cuts1=
rand_cuts2=
; similarly 'ones' signifies unit-weighting
; no syntax here, only FITS column-names; weights should be predefined
data_weights1=
	ones //
	some_weight_column
data_weights2=
rand_weights1=
rand_weights2=

[output]
savedir=./OUTPUTS/
; outfile names; row per correlation, otherwise default names will be given
; will be appended with .dat, if not already
out_corrs=
	wgg //
	wgp



